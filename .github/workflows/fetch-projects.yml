name: Fetch Projects Data

on:
  schedule:
    # Run daily at 2:00 AM UTC
    - cron: '0 2 * * *'
  workflow_dispatch: # Allow manual trigger
  push:
    branches:
      - main
    paths:
      - '.github/workflows/fetch-projects.yml'

jobs:
  fetch-and-update:
    runs-on: ubuntu-latest
    
    steps:
      - name: Checkout repository
        uses: actions/checkout@v3
        with:
          token: ${{ secrets.GITHUB_TOKEN }}
      
      - name: Set up Python
        uses: actions/setup-python@v4
        with:
          python-version: '3.11'
      
      - name: Install dependencies
        run: |
          pip install requests beautifulsoup4
      
      - name: Fetch projects data
        run: |
          python - <<'EOF'
          import requests
          from bs4 import BeautifulSoup
          import json
          import re
          from datetime import datetime

          print("ðŸš€ Fetching projects from staff profile...")
          
          STAFF_URL = 'https://people.ce.pdn.ac.lk/staff/academic/roshan-ragel/'
          
          try:
              # Fetch HTML
              response = requests.get(STAFF_URL, timeout=30)
              response.raise_for_status()
              print(f"âœ… Successfully fetched HTML ({len(response.text)} characters)")
              
              # Parse HTML
              soup = BeautifulSoup(response.text, 'html.parser')
              
              projects_by_batch = {}
              
              # Find all h5 headers (batch headers like "E19(13 projects)")
              all_h5 = soup.find_all('h5')
              print(f"Found {len(all_h5)} h5 elements")
              
              for heading in all_h5:
                  text = heading.get_text().strip()
                  
                  # Match pattern like "E19(13 projects)" or "E19 (13 projects)"
                  batch_match = re.match(r'E(\d{2})\s*\((\d+)\s*projects?\)', text, re.IGNORECASE)
                  
                  if batch_match:
                      batch = f"E{batch_match.group(1)}"
                      project_count = int(batch_match.group(2))
                      
                      print(f"âœ“ Found batch: {batch} with {project_count} projects")
                      
                      projects = []
                      sibling = heading.find_next_sibling()
                      
                      # Collect projects following this heading
                      while sibling and len(projects) < project_count:
                          # Look for h6 (project title) and link
                          title_element = sibling.find('h6')
                          link_element = sibling.find('a', href=lambda x: x and 'projects.ce.pdn.ac.lk' in x)
                          
                          if title_element and link_element:
                              projects.append({
                                  'title': title_element.get_text().strip(),
                                  'url': link_element.get('href')
                              })
                          
                          sibling = sibling.find_next_sibling()
                          
                          # Stop if we hit another h5
                          if sibling and sibling.name == 'h5':
                              break
                      
                      if projects:
                          projects_by_batch[batch] = projects
                          print(f"âœ… Added {len(projects)} projects for {batch}")
              
              # Add metadata
              output_data = {
                  'last_updated': datetime.utcnow().isoformat() + 'Z',
                  'total_projects': sum(len(p) for p in projects_by_batch.values()),
                  'total_batches': len(projects_by_batch),
                  'projects': projects_by_batch
              }
              
              # Save to JSON
              with open('projects-data.json', 'w', encoding='utf-8') as f:
                  json.dump(output_data, f, indent=2, ensure_ascii=False)
              
              print(f"\nâœ… Successfully saved {output_data['total_projects']} projects across {output_data['total_batches']} batches")
              print(f"ðŸ“Š Data saved to projects-data.json")
              
          except Exception as e:
              print(f"âŒ Error: {e}")
              raise
          EOF
      
      - name: Commit and push if changed
        run: |
          git config --local user.email "github-actions[bot]@users.noreply.github.com"
          git config --local user.name "github-actions[bot]"
          git add projects-data.json
          
          # Check if there are changes
          if git diff --staged --quiet; then
            echo "No changes to commit"
          else
            git commit -m "ðŸ¤– Auto-update: Fetch latest projects data"
            git push
            echo "âœ… Changes committed and pushed"
          fi
